{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ccRead Optimization \n",
    "\n",
    "Testing the feasibility of ccRead optimization through vectorization and use of comprehensions. To run this notebook place it in the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import random # for test sampling\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import numbers\n",
    "\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import plaidml.keras\n",
    "    plaidml.keras.install_backend()\n",
    "\n",
    "    from keras.models import load_model\n",
    "    import keras.backend as K\n",
    "except ImportError:\n",
    "    try:\n",
    "        from tensorflow.keras.models import load_model\n",
    "        from tensorflow.keras import backend as K\n",
    "    except ImportError:\n",
    "        from keras.models import load_model\n",
    "        import keras.backend as K\n",
    "    finally:\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "from PIL import Image, ImageCms\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import rawpy\n",
    "from rawpy import LibRawNonFatalError, LibRawFatalError\n",
    "\n",
    "position_model = load_model(\"libs/models/mlp_proposal.hdf5\")\n",
    "discriminator_model = load_model(\"libs/models/discriminator.hdf5\")\n",
    "high_precision_model = load_model(\"libs/models/highprecision_discriminator.hdf5\")\n",
    "#size_det_model = load_model(\"libs/models/size_model.hdf5\")\n",
    "#large_colorchip_regressor_model = load_model(\"libs/models/lcc_regressor.hdf5\")\n",
    "#size_model = load_model(\"libs/models/size_model.hdf5\")\n",
    "\n",
    "position_function = K.function(\n",
    "    [position_model.layers[0].input, position_model.layers[1].input, K.learning_phase()],\n",
    "    [position_model.layers[-1].output])\n",
    "\n",
    "discriminator_function = K.function([discriminator_model.layers[0].input, K.learning_phase()],\n",
    "                                         [discriminator_model.layers[-1].output])\n",
    "\n",
    "high_precision_discriminator_function = K.function([high_precision_model.layers[10].input,\n",
    "                                                         high_precision_model.layers[11].input,\n",
    "                                                         high_precision_model.layers[0].input,\n",
    "                                                         K.learning_phase()],\n",
    "                                                        [high_precision_model.layers[-1].output])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up base functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openImageFile(imgPath,\n",
    "                  demosaic=rawpy.DemosaicAlgorithm.AHD):\n",
    "    \"\"\" given an image path, attempts to return a numpy array image object\n",
    "    \"\"\"\n",
    "    usr_gamma = 2.2\n",
    "    gamma_value = (usr_gamma, usr_gamma)\n",
    "    try:  # use rawpy to convert raw to openCV\n",
    "        with rawpy.imread(imgPath) as raw:\n",
    "            im = raw.postprocess(chromatic_aberration=(1, 1),\n",
    "                                  demosaic_algorithm=demosaic,\n",
    "                                  gamma=gamma_value,\n",
    "                                  output_color=rawpy.ColorSpace.raw)\n",
    "\n",
    "    # if it is not a raw format, just try and open it.\n",
    "    except LibRawNonFatalError:\n",
    "        bgr = cv2.imread(imgPath)\n",
    "        im = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    except LibRawFatalError:\n",
    "        raise\n",
    "    return im\n",
    "\n",
    "def scale_images_with_info(im, largest_dim=1875):\n",
    "    \"\"\"\n",
    "    Function that scales images proportionally, and returns both the original image size as a tuple of image\n",
    "    dimensions, and the scaled down image.\n",
    "    :param im: Image to be scaled down.\n",
    "    :type im: cv2 Image\n",
    "    :param largest_dim: The largest dimension to be scaled down to.\n",
    "    :type largest_dim: int\n",
    "    :return: Returns both the original image dimensions as a tuple and the scaled image.\n",
    "    :rtype: tuple, cv2 Image\n",
    "    \"\"\"\n",
    "    image_height, image_width = im.shape[0:2]\n",
    "\n",
    "    if image_width > image_height:\n",
    "        reduced_im = cv2.resize(im, (largest_dim, round((largest_dim / image_width) * image_height)),\n",
    "                                interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        reduced_im = cv2.resize(im, (round((largest_dim / image_height) * image_width), largest_dim),\n",
    "                                interpolation=cv2.INTER_AREA)\n",
    "    return (image_width, image_height), reduced_im\n",
    "\n",
    "def _predict_uncertainty_position(x, n_iter=10):\n",
    "    \"\"\"\n",
    "    Predicts with uncertainty the position of a color chip using the mean and variance.\n",
    "\n",
    "    :param x: A list that contains both the RGB histogram and the HSV histogram of a given partition. Format of the\n",
    "    list should be [rgb_histogram, hsv_histogram]\n",
    "    :type x: list, ndarray\n",
    "    :param n_iter: Number of iterations for the results. Most often would be the length of the list of histograms,\n",
    "    though in a sorted list could be a value between 0 and length of list.\n",
    "    :type n_iter: int\n",
    "    :return: Returns the prediction and uncertainty. The prediction is a category exclusive probability.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        result.append(position_function([x[0], x[1], 1]))\n",
    "\n",
    "    result = np.array(result)\n",
    "    uncertainty = result.var(axis=0)\n",
    "    prediction = result.mean(axis=0)\n",
    "    return prediction, uncertainty\n",
    "\n",
    "def _predict_uncertainty_discriminator(x, n_iter=10):\n",
    "    \"\"\"\n",
    "    Predicts with uncertainty the probability that the given partition contains a color chip using the mean and\n",
    "    variance.\n",
    "\n",
    "    :param x: A list that contains both the RGB histogram and the HSV histogram of a given partition. Format of the\n",
    "    list should be [rgb_histogram, hsv_histogram]\n",
    "    :type x: list, ndarray\n",
    "    :param n_iter: Number of iterations for the results. Most often would be the length of the list of histograms,\n",
    "    though in a sorted list could be a value between 0 and length of list.\n",
    "    :type n_iter: int\n",
    "    :return: Returns the prediction and uncertainty. The prediction is a category exclusive probability.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        result.append(discriminator_function([x, 1]))\n",
    "\n",
    "    result = np.array(result)\n",
    "    uncertainty = result.var(axis=0)\n",
    "    prediction = result.mean(axis=0)\n",
    "    return prediction, uncertainty\n",
    "\n",
    "def _predict_uncertainty_hp_discriminator(x, n_iter=10):\n",
    "    \"\"\"\n",
    "    Predicts with uncertainty the probability that the given partition contains a color chip using the mean and\n",
    "    variance. This uses the high precision model, which is more robust against false positives if\n",
    "\n",
    "    Note: Currently, this model performs very poorly (relative to the normal discriminator model) against images\n",
    "    with drastic white balance shift.\n",
    "\n",
    "    :param x: A list that contains both the RGB histogram and the HSV histogram of a given partition. Format of the\n",
    "    list should be [rgb_histogram, hsv_histogram]\n",
    "    :type x: list, ndarray\n",
    "    :param n_iter: Number of iterations for the results. Most often would be the length of the list of histograms,\n",
    "    though in a sorted list could be a value between 0 and length of list.\n",
    "    :type n_iter: int\n",
    "    :return: Returns the prediction and uncertainty. The prediction is a category exclusive probability.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        result.append(high_precision_discriminator_function([x[0], x[1], x[2], 1]))\n",
    "\n",
    "    result = np.array(result)\n",
    "    uncertainty = result.var(axis=0)\n",
    "    prediction = result.mean(axis=0)\n",
    "    return prediction, uncertainty\n",
    "\n",
    "def ocv_to_pil(im):\n",
    "    \"\"\"\n",
    "    Converts an OCV image into PIL format. From\n",
    "    https://stackoverflow.com/questions/43232813/convert-opencv-image-format-to-pil-image-format?noredirect=1&lq=1\n",
    "    :param im: OpenCV image.\n",
    "    :type im:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    pil_image = np.array(im)\n",
    "    pil_image = Image.fromarray(pil_image)\n",
    "    return pil_image\n",
    "\n",
    "\n",
    "def cv2_rgb_hist(im_rgb):\n",
    "    \"\"\"\n",
    "    a helper function to give cv2's histogram calculation similar syntax and result as pil.histogram()\n",
    "    \"\"\"\n",
    "    hists = [cv2.calcHist([im_rgb], [channel], None, [256], [0, 256]).astype(int) for channel in [0,1,2]]\n",
    "    pil_style_hist = np.concatenate(hists, axis=None)\n",
    "\n",
    "    return pil_style_hist\n",
    "   \n",
    "def cv2_hsv_hist(im_hsv):\n",
    "    \"\"\"\n",
    "    a helper function to give cv2's histogram calculation similar syntax and result as pil.histogram()\n",
    "    \"\"\"\n",
    "    hists = [cv2.calcHist([im_hsv], [channel], None, [256], [0, 256]).astype(int) for channel in [0,1,2]]\n",
    "    pil_style_hist = np.concatenate(hists, axis=None)\n",
    "\n",
    "    return pil_style_hist\n",
    "\n",
    "@jit\n",
    "def np_img_crop(im, crop_box ):\n",
    "    \"\"\"\n",
    "    im = numpy array image\n",
    "    crop_box = a 4-tuple defining the left, upper, right, and lower pixel coordinate (inclusive)\n",
    "        e.g.: x1, y1, x2, y2\n",
    "    a helper function to give numpy image cropping similar syntax to PIL cropping.\n",
    "    Note: PIL is inclusive, if you want 46x46: use (0, 0, 46, 46).\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = crop_box\n",
    "    # no values should be < 0\n",
    "    y1 = max([0, y1-1])\n",
    "    x1 = max([0, x1-1])\n",
    "    # no values should be > the resolution max\n",
    "    h_max, w_max = im.shape[0:2]\n",
    "    y2 = min([h_max, y2+1])\n",
    "    x2 = min([w_max, x2+1])\n",
    "    #  Numpy indexing is exclusive, solve that\n",
    "    return im[y1:y2, x1:x2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the `predict_color_chip_whitevals`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict_color_chip_whitevals(color_chip_image):\n",
    "    \"\"\"\n",
    "    Takes the white values within the cropped CC image and averages them in RGB. The whitest values in the image is\n",
    "    determined in the L*a*b color space, wherein only lightness values higher than (max lightness value - 1) is\n",
    "    considered\n",
    "    \n",
    "    :param color_chip_image: The cropped color chip image.\n",
    "    :type color_chip_image: Image\n",
    "    :return: Returns a list of the averaged whitest values\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    \n",
    "    cci_array = np.array(color_chip_image)\n",
    "    ccil_array = cv2.cvtColor(color_chip_image, cv2.COLOR_RGB2Lab)\n",
    "    width, height = ccil_array.shape[0], ccil_array.shape[1]\n",
    "    # id max_lightness in ccil (lab space)\n",
    "    max_lightness = ccil_array[...,0].max()\n",
    "    # index cci_array based on conditions met in ccil_array\n",
    "    white_pixels_rgbvals = cci_array[ ccil_array[...,0]> max_lightness-1]\n",
    "    # det \n",
    "    white_pixels_average = np.average(white_pixels_rgbvals, axis=0)\n",
    "\n",
    "    return list(white_pixels_average)\n",
    "\n",
    "def predict_color_chip_whitevals(color_chip_image):\n",
    "    \"\"\"\n",
    "    Takes the white values within the cropped CC image and averages them in RGB. The whitest values in the image is\n",
    "    determined in the L*a*b color space, wherein only lightness values higher than (max lightness value - 1) is\n",
    "    considered\n",
    "\n",
    "    Converting from RGB to LAB color space is not supported under PIL, but was done through a solution from:\n",
    "    https://gist.github.com/mrkn/28f95f95731a5a24e553\n",
    "    :param color_chip_image: The cropped color chip image.\n",
    "    :type color_chip_image: Image\n",
    "    :return: Returns a list of the averaged whitest values\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    cci_array = np.array(color_chip_image)\n",
    "\n",
    "    srgb_profile = ImageCms.createProfile(\"sRGB\")\n",
    "    lab_profile = ImageCms.createProfile(\"LAB\")\n",
    "    rgb2lab_transform = ImageCms.buildTransformFromOpenProfiles(srgb_profile, lab_profile, \"RGB\", \"LAB\")\n",
    "    color_chip_image_lab = ImageCms.applyTransform(color_chip_image, rgb2lab_transform)\n",
    "\n",
    "    ccil_array = np.array(color_chip_image_lab)\n",
    "    width, height = ccil_array.shape[0], ccil_array.shape[1]\n",
    "\n",
    "    lightness_dict = {}\n",
    "    for row in range(width):\n",
    "        for column in range(height):\n",
    "            lightness = ccil_array[row][column][0]\n",
    "            lightness_dict[(row, column)] = lightness\n",
    "\n",
    "    max_lightness = max(list(lightness_dict.values()))\n",
    "    white_pixels_indices = []\n",
    "    for idx, lightness in enumerate(list(lightness_dict.values())):\n",
    "        if lightness > (max_lightness - 1):\n",
    "            white_pixels_indices.append(list(lightness_dict.keys())[idx])\n",
    "\n",
    "    white_pixels_rgbvals = []\n",
    "    for index in white_pixels_indices:\n",
    "        row, column = index[0], index[1]\n",
    "        white_pixels_rgbvals.append(cci_array[row][column])\n",
    "\n",
    "    white_pixels_nparray = np.array(white_pixels_rgbvals)\n",
    "    white_pixels_average = np.average(white_pixels_nparray, axis=0)\n",
    "\n",
    "    return list(white_pixels_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 1707, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imPath = './exampleImages/various_images/color_chip.jpg'\n",
    "im = openImageFile(imPath)\n",
    "original_size, img = scale_images_with_info(im)\n",
    "display(img.shape)\n",
    "img = im.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[254.25, 210.25, 158.25]\n",
      "0.006119966506958008\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(test_predict_color_chip_whitevals(im))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg from test func: 0.0020266452638229523\n",
      "avg from orig func: 0.7686132157202994\n"
     ]
    }
   ],
   "source": [
    "test_times = []\n",
    "orig_times = []\n",
    "for i in range(0, 101):\n",
    "    start = time.time()\n",
    "    test_predict_color_chip_whitevals(im)\n",
    "    test_times.append(time.time() - start)\n",
    "\n",
    "    img = ocv_to_pil(img)\n",
    "    start = time.time()\n",
    "    predict_color_chip_whitevals(img)\n",
    "    orig_times.append(time.time() - start)\n",
    "\n",
    "avg_test = np.mean(test_times)\n",
    "avg_orig = np.mean(orig_times)\n",
    "print(f'avg from test func: {avg_test}')\n",
    "print(f'avg from orig func: {avg_orig}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### results\n",
    "`test_predict_color_chip_whitevals` appears much improved. However, the slight differences in the values is worthy of consideration. Possibly related to pil conversions. It is also worth verifying the colorspace is RGB at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
